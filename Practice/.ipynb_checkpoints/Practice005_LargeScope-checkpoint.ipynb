{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pygame, sys, random\n",
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "\n",
    "num_episodes = 1\n",
    "\n",
    "agentRadius = 10\n",
    "\n",
    "# get size of state and action from environment\n",
    "\n",
    "boundaryPos = [400, 590]\n",
    "boundaryLength = [70, 70]\n",
    "initPosAgent = [boundaryPos[0] + boundaryLength[0] / 2, boundaryPos[1] + boundaryLength[1] / 2]#[boundaryPos[0], boundaryPos[1] + boundaryLength[1]]\n",
    "goalPos = [boundaryPos[0] + boundaryLength[0], boundaryPos[1]]\n",
    "\n",
    "moveObstacles = True\n",
    "action_size = 9\n",
    "obsNumber = 2\n",
    "# state_size = obsNumber * 2 + 1\n",
    "state_size = 3\n",
    "# state_size = obsNumber + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A2C(Advantage Actor-Critic) agent\n",
    "class A2CAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.load_model = True\n",
    "        # get size of state and action\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.value_size = 1\n",
    "\n",
    "        # These are hyper parameters for the Policy Gradient\n",
    "        self.discount_factor = 0.99\n",
    "        self.actor_lr = 0.00002\n",
    "        self.critic_lr = 0.00005\n",
    "\n",
    "        # create model for policy network\n",
    "        self.actor = self.build_actor()\n",
    "        self.critic = self.build_critic()\n",
    "\n",
    "        if self.load_model:\n",
    "            self.actor.load_weights(\"./Practice004_DataSave/Actor.h5\")\n",
    "            self.critic.load_weights(\"./Practice004_DataSave/Critic.h5\")\n",
    "\n",
    "    # approximate policy and value using Neural Network\n",
    "    # actor: state is input and probability of each action is output of model\n",
    "    def build_actor(self):\n",
    "        actor = Sequential()\n",
    "        actor.add(Dense(128, input_dim=self.state_size, activation='relu', kernel_initializer='glorot_normal'))\n",
    "        actor.add(Dense(self.action_size, activation='softmax', kernel_initializer='glorot_normal'))\n",
    "        actor.summary()\n",
    "        # See note regarding crossentropy in cartpole_reinforce.py\n",
    "        actor.compile(loss='categorical_crossentropy', optimizer=Adam(lr=self.actor_lr))\n",
    "        return actor\n",
    "\n",
    "    # critic: state is input and value of state is output of model\n",
    "    def build_critic(self):\n",
    "        critic = Sequential()\n",
    "        critic.add(Dense(128, input_dim=self.state_size, activation='relu', kernel_initializer='glorot_normal'))\n",
    "        critic.add(Dense(self.value_size, activation='linear', kernel_initializer='glorot_normal'))\n",
    "        critic.summary()\n",
    "        critic.compile(loss=\"mse\", optimizer=Adam(lr=self.critic_lr))\n",
    "        return critic\n",
    "\n",
    "    # using the output of policy network, pick action stochastically\n",
    "    def get_action(self, state):\n",
    "        policy = self.actor.predict(state, batch_size=1).flatten()\n",
    "        # Policy = 확률. 이 확률에 맞게 Action을 선택\n",
    "        print policy\n",
    "        return np.random.choice(self.action_size, 1, p=policy)[0]\n",
    "#         return policy\n",
    "\n",
    "    # update policy network every episode\n",
    "    def train_model(self, state, action, reward, next_state, done):\n",
    "        target = np.zeros((1, self.value_size))\n",
    "        advantages = np.zeros((1, self.action_size))\n",
    "\n",
    "        value = self.critic.predict(state)[0]\n",
    "        next_value = self.critic.predict(next_state)[0]\n",
    "\n",
    "        if done:\n",
    "            advantages[0][action] = reward - value\n",
    "            target[0][0] = reward\n",
    "        else:\n",
    "            advantages[0][action] = reward + self.discount_factor * (next_value) - value\n",
    "            target[0][0] = reward + self.discount_factor * next_value\n",
    "\n",
    "        self.actor.fit(state, advantages, epochs=1, verbose=0)\n",
    "        self.critic.fit(state, target, epochs=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ckWall(xPos, yPos):\n",
    "    flagWall = 0\n",
    "    if(xPos < boundaryPos[0]):\n",
    "        xPos = boundaryPos[0]\n",
    "        flagWall = -1\n",
    "    elif(xPos > boundaryPos[0] + boundaryLength[0]):\n",
    "        xPos = boundaryPos[0] + boundaryLength[0]\n",
    "        flagWall = -1\n",
    "    if(yPos < boundaryPos[1]):\n",
    "        yPos = boundaryPos[1]\n",
    "        flagWall = -1\n",
    "    elif(yPos > boundaryPos[1] + boundaryLength[1]):\n",
    "        yPos = boundaryPos[1] + boundaryLength[1]\n",
    "        flagWall = -1\n",
    "        \n",
    "    return [xPos, yPos, flagWall]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ckInit(initLoc, obsLoc):\n",
    "    if math.sqrt((initLoc[0] - obsLoc[0])**2 + (initLoc[1] - obsLoc[1])**2) <= 2*agentRadius + 1:\n",
    "        if initLoc[0] - obsLoc[0] < 0:\n",
    "            obsLoc[0] += 1\n",
    "        else:\n",
    "            obsLoc[0] -= 1\n",
    "        if initLoc[1] - obsLoc[1] < 0:\n",
    "            obsLoc[1] += 1\n",
    "        else:\n",
    "            obsLoc[1] -= 1\n",
    "    if math.sqrt((goalPos[0] - obsLoc[0])**2 + (goalPos[1] - obsLoc[1])**2) <= 2*agentRadius + 1:\n",
    "        obsLoc[0] -= 1\n",
    "        obsLoc[1] += 1\n",
    "    return obsLoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stateGenerator(obsPosition, agtPosition, idx):\n",
    "    returnSum = []\n",
    "    returnSum = returnSum + [agtPosition[0] - obsPosition[idx][0], agtPosition[1] - obsPosition[idx][1]]\n",
    "    returnSum = returnSum + [math.sqrt((agtPosition[0] - goalPos[0])**2 + (agtPosition[1] - goalPos[1])**2)]\n",
    "    returnSum = np.reshape(returnSum, [1, 3])\n",
    "    return returnSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ckCollision(obsPosition, agtPosition):\n",
    "    for i in range(0,obsNumber):\n",
    "        if math.sqrt((agtPosition[0] - obsPosition[i][0])**2 + (agtPosition[1] - obsPosition[i][1])**2) <= 20:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def takeAction(action):\n",
    "    xAction = 0\n",
    "    yAction = 0\n",
    "    if action == 0:\n",
    "        xAction = 1\n",
    "    elif action == 1:\n",
    "        xAction = 1\n",
    "        yAction = 1\n",
    "    elif action == 2:\n",
    "        xAction = 1\n",
    "        yAction = -1            \n",
    "    elif action == 3:\n",
    "        xAction = -1\n",
    "        yAction = 1\n",
    "    elif action == 4:\n",
    "        xAction = -1\n",
    "    elif action == 5:\n",
    "        xAction = -1\n",
    "        yAction = -1\n",
    "    elif action == 6:\n",
    "        yAction = -1\n",
    "    elif action == 7:\n",
    "        yAction = 1\n",
    "    elif action  == 8:\n",
    "        xAction = 0\n",
    "        yAction = 0\n",
    "        \n",
    "    return [xAction, yAction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_361 (Dense)            (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_362 (Dense)            (None, 9)                 1161      \n",
      "=================================================================\n",
      "Total params: 1,673\n",
      "Trainable params: 1,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_363 (Dense)            (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_364 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 641\n",
      "Trainable params: 641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "('Episode ', 0, 'Starts!')\n",
      "[  1.24634998e-05   2.30131283e-01   4.91042703e-01   4.98015084e-38\n",
      "   3.80400419e-02   1.59629919e-02   1.14042819e-01   2.15575509e-02\n",
      "   8.92101824e-02]\n",
      "[  8.40274055e-08   7.97343999e-03   9.73434210e-01   0.00000000e+00\n",
      "   9.51456488e-04   1.68952174e-04   4.36663067e-05   5.57392277e-03\n",
      "   1.18544511e-02]\n",
      "=====================================================\n",
      "[  2.43425893e-05   3.34467858e-01   2.63496041e-01   1.48021988e-35\n",
      "   8.34674239e-02   3.33067141e-02   1.12167828e-01   4.90210056e-02\n",
      "   1.24048635e-01]\n",
      "[  5.40204574e-08   3.92457284e-03   9.84108746e-01   0.00000000e+00\n",
      "   5.53064863e-04   1.25375111e-04   2.38965149e-05   3.53388954e-03\n",
      "   7.73030426e-03]\n",
      "=====================================================\n",
      "[  3.24399625e-05   3.37494105e-01   2.91203469e-01   1.19002697e-34\n",
      "   7.27844164e-02   2.66482104e-02   1.11278042e-01   4.31276150e-02\n",
      "   1.17431745e-01]\n",
      "[  7.51739115e-09   3.54354474e-04   9.97272909e-01   0.00000000e+00\n",
      "   7.65909863e-05   3.30356270e-05   3.22153619e-06   5.46507654e-04\n",
      "   1.71330513e-03]\n",
      "=====================================================\n",
      "[  4.19948956e-05   3.66963655e-01   3.69149715e-01   5.01529302e-34\n",
      "   5.08691818e-02   1.22847054e-02   8.70521888e-02   2.94590220e-02\n",
      "   8.41796920e-02]\n",
      "[  7.73299536e-10   1.61530497e-05   9.99694586e-01   0.00000000e+00\n",
      "   7.99618556e-06   8.07761444e-06   2.89130071e-07   6.78948927e-05\n",
      "   2.05067263e-04]\n",
      "=====================================================\n",
      "[  7.19399904e-05   4.81278330e-01   1.67673960e-01   1.25271481e-31\n",
      "   9.33043286e-02   2.22989284e-02   7.49732777e-02   5.85565381e-02\n",
      "   1.01842657e-01]\n",
      "[  8.43081382e-10   1.27909616e-05   9.99726832e-01   0.00000000e+00\n",
      "   8.48079526e-06   1.04172414e-05   2.69778042e-07   7.50054242e-05\n",
      "   1.66298923e-04]\n",
      "=====================================================\n",
      "Collision!\n",
      "-10000.4\n"
     ]
    }
   ],
   "source": [
    "pygame.init()\n",
    "screen = pygame.display.set_mode([1280,960])\n",
    "screen.fill([200, 200, 200])\n",
    "\n",
    "# make A2C agent\n",
    "agent = A2CAgent(state_size, action_size)\n",
    "\n",
    "rList, episodes = [], []\n",
    "\n",
    "# Make Obstacles (obsNumber)\n",
    "obstaclePos = [[0, 0] for _ in range(obsNumber)]\n",
    "for i in range(0,obsNumber):\n",
    "    while True:\n",
    "        obstaclePos[i][0] = boundaryPos[0] + random.randrange(1, boundaryLength[0])\n",
    "        obstaclePos[i][1] = boundaryPos[1] + random.randrange(1, boundaryLength[1])\n",
    "        if obstaclePos[i][0] <= goalPos[0] - agentRadius or obstaclePos[i][0] >= goalPos[0] + agentRadius:\n",
    "            if obstaclePos[i][1] >= goalPos[1] + agentRadius or obstaclePos[i][1] <= goalPos[1] - agentRadius:\n",
    "                if obstaclePos[i][0] <= initPosAgent[0] - agentRadius or obstaclePos[i][0] >= initPosAgent[0] + agentRadius:\n",
    "                    if obstaclePos[i][1] >= initPosAgent[1] + agentRadius or obstaclePos[i][1] <= initPosAgent[1] - agentRadius:\n",
    "                        break\n",
    "\n",
    "for e in range(num_episodes):\n",
    "    # Initialize\n",
    "    done = False\n",
    "    score = 0\n",
    "    x = initPosAgent[0]#boundaryPos[0]\n",
    "    y = initPosAgent[1]#boundaryPos[1]\n",
    "    print(\"Episode \", e, \"Starts!\")\n",
    "    #state = np.reshape(state, [1, state_size])\n",
    "    tmpX = 0\n",
    "    tmpY = 0\n",
    "    while not done:\n",
    "        getPolicy = []\n",
    "#         tmpPolicyA = []\n",
    "#         tmpPolicyB = []\n",
    "        \n",
    "        for i in range(0, obsNumber):\n",
    "            state = stateGenerator(obstaclePos, [x,y], i)\n",
    "#             [action, badAction] = agent.get_action(state)\n",
    "#             tmpPolicyA = np.log(agent.get_action(state))\n",
    "            action = agent.get_action(state)\n",
    "#             if(i > 0):\n",
    "#                 getPolicy = np.add(tmpPolicyA, getPolicy)\n",
    "#                 getPolicy = np.multiply(tmpPolicyA, getPolicy)\n",
    "#             else:\n",
    "#                 getPolicy = tmpPolicyA\n",
    "#             print(\"Local\",i,\":\", tmpPolicyA)\n",
    "#         getPolicy = np.exp(getPolicy)\n",
    "#         getPolicy = getPolicy / sum(getPolicy)\n",
    "#             action = np.random.choice(action_size, 1, p = getPolicy)[0]\n",
    "#         print(\"Total:\", getPolicy)\n",
    "            \n",
    "            xMove = 0\n",
    "            yMove = 0\n",
    "\n",
    "            [xMove, yMove] = takeAction(action)\n",
    "            \n",
    "#             tmpX = tmpX + xMove\n",
    "#             tmpY = tmpY + yMove\n",
    "            x = x + xMove\n",
    "            y = y + yMove\n",
    "            \n",
    "            if ckCollision(obstaclePos, [x,y], i) == True:\n",
    "                print(\"Collision Predicted!\")\n",
    "                x = x - xMove\n",
    "                y = y - yMove\n",
    "            \n",
    "            wallFlag = 0\n",
    "            collisionFlag = 0\n",
    "#         if tmpX != 0 or tmpY != 0:\n",
    "#             x = int(round(x + tmpX / math.sqrt(tmpX**2 + tmpY**2)))\n",
    "#             y = int(round(y + tmpY / math.sqrt(tmpX**2 + tmpY**2)))\n",
    "        print \"=====================================================\"\n",
    "        [x, y, wallFlag] = ckWall(x,y)\n",
    "        pygame.draw.circle(screen, [100, 100, 255], [x,y], 10, 0)\n",
    "#         next_state = stateGenerator(obstaclePos, [x,y])\n",
    "\n",
    "        if(math.sqrt((x - goalPos[0])**2 + (y - goalPos[1])**2) <= 20):\n",
    "            print(\"Goal Reached!\")           \n",
    "            collisionFlag = 1\n",
    "            done = 1\n",
    "                \n",
    "        for i in range(0,obsNumber):\n",
    "            if moveObstacles:\n",
    "                obstaclePos[i][0] = obstaclePos[i][0] + random.randrange(-1,2)\n",
    "                obstaclePos[i][1] = obstaclePos[i][1] + random.randrange(-1,2)\n",
    "                [obstaclePos[i][0], obstaclePos[i][1], _] = ckWall(obstaclePos[i][0], obstaclePos[i][1])\n",
    "                obstaclePos[i] = ckInit(initPosAgent ,obstaclePos[i])\n",
    "\n",
    "            pygame.draw.circle(screen, [255, 50 + 20*i, 50 + 20 * i], obstaclePos[i], 10, 0)\n",
    "            if math.sqrt((x - obstaclePos[i][0])**2 + (y - obstaclePos[i][1])**2) <= 20:\n",
    "                print(\"Collision!\")\n",
    "                collisionFlag = -1\n",
    "                ObjectIndex = i\n",
    "                done = True \n",
    "#         if wallFlag == -1:\n",
    "#             done = True\n",
    "            \n",
    "        if not done:\n",
    "            reward = -0.1\n",
    "            if wallFlag == -1:\n",
    "                reward = -1\n",
    "        else:\n",
    "            if collisionFlag == 1:\n",
    "                reward = 10000\n",
    "                rList.append(1)\n",
    "            elif collisionFlag == -1:\n",
    "                reward = -10000\n",
    "                rList.append(0)\n",
    "#             next_state, reward, done, ininitPosAgentfo = env.step(action)\n",
    "#             next_state = np.reshape(next_state, [1, state_size])\n",
    "        # if an action make the episode end, then gives penalty of -100\n",
    "#             reward = reward if not done or score == 499 else -100\n",
    "        \n",
    "#         agent.train_model(state, action, reward, next_state, done)\n",
    "\n",
    "        score += reward\n",
    "#         state = next_state\n",
    "\n",
    "        if done:\n",
    "            # every episode, plot the play time\n",
    "\n",
    "            episodes.append(e)\n",
    "            pylab.plot(episodes, rList, 'b')\n",
    "#             pylab.savefig(\"./Practice004_DataSave/ActorCriticGraph_Test.png\")\n",
    "        #circle(Surface, color, pos, radius, width=0)\n",
    "        pygame.draw.circle(screen, [100,255,100], [goalPos[0],goalPos[1]], 10, 2)\n",
    "        #rect(Surface, color, Rect, width=0)\n",
    "        pygame.draw.rect(screen, [255,100,100],[boundaryPos[0] - agentRadius, boundaryPos[1] - agentRadius, boundaryLength[0] + agentRadius * 2, boundaryLength[1] + agentRadius * 2],2)\n",
    "        pygame.display.flip()\n",
    "        screen.fill([200,200,200])\n",
    "    print score\n",
    "    # save the model\n",
    "#     if e % 50 == 0:\n",
    "#         agent.actor.save_weights(\"./Practice004_DataSave/Actor.h5\")\n",
    "#         agent.critic.save_weights(\"./Practice004_DataSave/Critic.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of successful episodes: 70.0%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc9b064ecd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Percent of successful episodes: \" + str(100.0 * sum(rList)/num_episodes) + \"%\")\n",
    "\n",
    "plt.bar(range(len(rList)), rList, color = \"Blue\", width = 0.00001)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
