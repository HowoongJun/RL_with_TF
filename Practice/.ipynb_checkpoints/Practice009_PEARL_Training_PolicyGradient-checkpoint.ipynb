{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pygame, sys, random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_episodes = 3601\n",
    "dis = 0.9\n",
    "rList = []\n",
    "\n",
    "obstacleRadius = 10\n",
    "agentRadius = 10\n",
    "\n",
    "# get size of state and action from environment\n",
    "\n",
    "boundaryPos = [80, 80]\n",
    "boundaryLength = [200,200]\n",
    "initPosAgent = [boundaryPos[0] + boundaryLength[0] / 2 + 100, boundaryPos[1] + boundaryLength[1] / 2]\n",
    "initPosGoal =  [boundaryPos[0] + boundaryLength[0] / 2, boundaryPos[1] + boundaryLength[1] / 2]\n",
    "\n",
    "moveObstacles = False\n",
    "action_size = 9\n",
    "obsNumber = 4\n",
    "state_size = 2\n",
    "obsAngleUnit = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_x:0\", shape=(?, 2), dtype=float32)\n",
      "<tf.Variable 'W1:0' shape=(2, 9) dtype=float32_ref>\n",
      "Tensor(\"Placeholder:0\", shape=(?, 9), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 2\n",
    "learning_rate = 0.1\n",
    "\n",
    "# X = tf.placeholder(tf.float32,  [None, state_size], name = \"input_x\")\n",
    "# W1 = tf.get_variable(\"W1\", shape = [state_size, hidden_size], initializer = tf.contrib.layers.xavier_initializer())\n",
    "# layer1 = tf.nn.tanh(tf.matmul(X, W1))\n",
    "# W2 = tf.get_variable(\"W2\", shape = [hidden_size, action_size], initializer = tf.contrib.layers.xavier_initializer())\n",
    "X = tf.placeholder(tf.float32,  [None, state_size], name = \"input_x\")\n",
    "W1 = tf.get_variable(\"W1\", shape = [state_size, action_size], initializer = tf.contrib.layers.xavier_initializer())\n",
    "# Qpred = tf.nn.tanh(tf.matmul(X, W1))\n",
    "\n",
    "Qpred = tf.matmul(X,W1)\n",
    "\n",
    "Y = tf.placeholder(shape  = [None, action_size], dtype = tf.float32)\n",
    "\n",
    "loss = tf.reduce_sum(tf.square(Y - Qpred))\n",
    "train = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ckWall(xPos, yPos):\n",
    "    flagWall = 0\n",
    "    if(xPos < boundaryPos[0]):\n",
    "        xPos = boundaryPos[0]\n",
    "        flagWall = -1\n",
    "    elif(xPos > boundaryPos[0] + boundaryLength[0]):\n",
    "        xPos = boundaryPos[0] + boundaryLength[0]\n",
    "        flagWall = -1\n",
    "    if(yPos < boundaryPos[1]):\n",
    "        yPos = boundaryPos[1]\n",
    "        flagWall = -1\n",
    "    elif(yPos > boundaryPos[1] + boundaryLength[1]):\n",
    "        yPos = boundaryPos[1] + boundaryLength[1]\n",
    "        flagWall = -1\n",
    "    return [int(round(xPos)), int(round(yPos)), flagWall]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def takeAction(action):\n",
    "    xAction = 0\n",
    "    yAction = 0\n",
    "    if action == 0:\n",
    "        xAction = 1\n",
    "    elif action == 1:\n",
    "        xAction = 1\n",
    "        yAction = 1\n",
    "    elif action == 2:\n",
    "        xAction = 1\n",
    "        yAction = -1\n",
    "    elif action == 3:\n",
    "        xAction = -1\n",
    "        yAction = 1\n",
    "    elif action == 4:\n",
    "        xAction = -1\n",
    "    elif action == 5:\n",
    "        xAction = -1\n",
    "        yAction = -1\n",
    "    elif action == 6:\n",
    "        yAction = -1\n",
    "    elif action == 7:\n",
    "        yAction = 1\n",
    "    elif action == 8:\n",
    "        xAction = 0\n",
    "        yAction = 0\n",
    "        \n",
    "    return [xAction, yAction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stateGenerator(intenPref, distPref):\n",
    "    returnSum = [intenPref, distPref]\n",
    "    returnSum = np.reshape(returnSum, [1, state_size])\n",
    "#     print returnSum\n",
    "    return returnSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rangeFinder(allObsPos, rangeCenter):\n",
    "    allObsAgtDistance = [0 for _ in range(obsNumber)]\n",
    "    for i in range(0, obsNumber):\n",
    "        allObsAgtDistance[i] = math.sqrt((allObsPos[i][0] - rangeCenter[0])**2 + (allObsPos[i][1] - rangeCenter[1])**2)\n",
    "    index = np.argmin(allObsAgtDistance)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Episode ', 0, 'Starts!')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-34044983bf43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m                     \u001b[0mrList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mQinput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mQs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/howoongjun/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/howoongjun/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/howoongjun/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/howoongjun/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/howoongjun/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#display\n",
    "pygame.init()\n",
    "screen = pygame.display.set_mode([300,300])\n",
    "screen.fill([200, 200, 200])\n",
    "\n",
    "obsAngleIdx = 0\n",
    "# Make Obstacles (obsNumber)\n",
    "obstaclePos = [[0, 0] for _ in range(obsNumber)]\n",
    "posOffset = 60\n",
    "obstaclePos[0][0] = int(initPosGoal[0] + posOffset) \n",
    "obstaclePos[0][1] = int(initPosGoal[1]) \n",
    "obstaclePos[1][0] = int(initPosGoal[0]) \n",
    "obstaclePos[1][1] = int(initPosGoal[1] + posOffset) \n",
    "obstaclePos[2][0] = int(initPosGoal[0] - posOffset) \n",
    "obstaclePos[2][1] = int(initPosGoal[1]) \n",
    "obstaclePos[3][0] = int(initPosGoal[0]) \n",
    "obstaclePos[3][1] = int(initPosGoal[1] - posOffset) \n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        done = False\n",
    "        score = 0\n",
    "        x = initPosAgent[0]\n",
    "        y = initPosAgent[1]\n",
    "        print(\"Episode \", episode, \"Starts!\")\n",
    "        \n",
    "        xMove = 0\n",
    "        yMove = 0\n",
    "        idx = rangeFinder(obstaclePos, [x,y])\n",
    "        FeatureVec1 = (x - initPosGoal[0])**2 + (y - initPosGoal[1])**2\n",
    "        FeatureVec2 = 1 / (0.2 + (x - obstaclePos[idx][0])**2 + (y - obstaclePos[idx][1])**2)\n",
    "        state = stateGenerator(FeatureVec1, FeatureVec2)\n",
    "\n",
    "#         e = 1.0 / ((episode/100.0) + 1.0)\n",
    "        e = 0.2\n",
    "#        e = 1.0 / (1.0 + episode / 40.0)\n",
    "        rAll = 0\n",
    "        step_count = 0\n",
    "\n",
    "        while not done:\n",
    "            step_count += 1\n",
    "            Qinput = np.reshape(state, [1, state_size])\n",
    "            Qs = sess.run(Qpred, feed_dict = {X: Qinput})\n",
    "\n",
    "#             if np.random.rand(1) < e:\n",
    "#                 action = random.randrange(0,8)\n",
    "#             else:\n",
    "            action = np.argmax(Qs)\n",
    "            \n",
    "            xMove = 0\n",
    "            yMove = 0\n",
    "            [xMove, yMove] = takeAction(action)\n",
    "\n",
    "            x = x + xMove\n",
    "            y = y + yMove\n",
    "            \n",
    "            wallFlag = 0\n",
    "            collisionFlag = 0\n",
    "            [x, y, wallFlag] = ckWall(x, y)\n",
    "            if wallFlag == -1:\n",
    "                action = 8\n",
    "            pygame.draw.circle(screen, [100,100,255],[x,y],agentRadius,0)\n",
    "            idx = rangeFinder(obstaclePos, [x,y])\n",
    "            FeatureVec1 = (x - initPosGoal[0])**2 + (y - initPosGoal[1])**2\n",
    "            FeatureVec2 = 1 / (0.2 + (x - obstaclePos[idx][0])**2 + (y - obstaclePos[idx][1])**2)\n",
    "            next_state = stateGenerator(FeatureVec1, FeatureVec2)\n",
    "            ## Draw Environment (Obstacle + Map)\n",
    "            if(math.sqrt((x - initPosGoal[0])**2 + (y - initPosGoal[1])**2) <= obstacleRadius + agentRadius):\n",
    "                print(\"Goal Reached!\")\n",
    "                reward = 20\n",
    "                collisionFlag = 1\n",
    "                done = True\n",
    "            for i in range(0,obsNumber):\n",
    "                pygame.draw.circle(screen, [255, 50, 50], obstaclePos[i], obstacleRadius, 0)\n",
    "                if math.sqrt((x - obstaclePos[i][0])**2 + (y - obstaclePos[i][1])**2) <= obstacleRadius + agentRadius:\n",
    "                    print(\"Collision!\", idx)\n",
    "                    reward = -30\n",
    "                    collisionFlag = -1\n",
    "                    done = True\n",
    "                    break\n",
    "            if not done:\n",
    "                reward = -1.0 * ((x - initPosGoal[0])**2 + (y - initPosGoal[1])**2) / 100000.0\n",
    "   #             reward = 0\n",
    "                Qinput1 = np.reshape(next_state, [1, state_size])\n",
    "                Qs1 = sess.run(Qpred, feed_dict = {X: Qinput1})\n",
    "                Qs[0,action] = reward + dis * np.max(Qs1)\n",
    "            else:\n",
    "                if collisionFlag == 1:\n",
    "                    Qs[0, action] = 20\n",
    "                    rList.append(1)\n",
    "                elif collisionFlag == -1:\n",
    "                    Qs[0, action] = -30\n",
    "                    rList.append(0)\n",
    "            \n",
    "            sess.run(train, feed_dict={X: Qinput, Y: Qs})\n",
    "            state = next_state\n",
    "            \n",
    "            if done:\n",
    "                for i in range(0,obsNumber):\n",
    "                    pygame.draw.circle(screen, [255, 50, 50], obstaclePos[i], obstacleRadius, 0)\n",
    "            pygame.draw.circle(screen, [100,255,100], initPosGoal, 10, 1)\n",
    "            pygame.draw.rect(screen, [255,100,100],[boundaryPos[0],boundaryPos[1], boundaryLength[0], boundaryLength[1]],1)\n",
    "            pygame.display.flip()\n",
    "            screen.fill([200,200,200])\n",
    "        print(\"Episode : {}, Object Index: {}\".format(episode, idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Percent of successful episodes: \" + str(sum(rList)/num_episodes) + \"%\")\n",
    "plt.bar(range(len(rList)), rList, color = \"white\", width = 0.00001)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
