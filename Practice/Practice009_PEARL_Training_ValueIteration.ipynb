{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pygame, sys, random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_episodes = 1001\n",
    "dis = 0.9\n",
    "rList = []\n",
    "\n",
    "obstacleRadius = 10\n",
    "agentRadius = 5\n",
    "goalRadius = 10\n",
    "# get size of state and action from environment\n",
    "\n",
    "boundaryPos = [50, 50]\n",
    "boundaryLength = [200,200]\n",
    "initPosAgent = [boundaryPos[0] + boundaryLength[0] / 2 + 20, boundaryPos[1] + boundaryLength[1] / 2 + 20]\n",
    "initPosAgentTmp = initPosAgent\n",
    "initPosGoal =  [boundaryPos[0] + boundaryLength[0] / 2, boundaryPos[1] + boundaryLength[1] / 2]\n",
    "\n",
    "moveObstacles = False\n",
    "action_size = 9\n",
    "obsNumber = 4\n",
    "state_size = 2\n",
    "hidden_size = 128\n",
    "obsAngleUnit = 1\n",
    "hidden_size = 2\n",
    "learning_rate = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_variable(scope_name, var_name, shape):\n",
    "    with tf.variable_scope(scope_name) as scope:\n",
    "        v = tf.get_variable(var_name, shape)\n",
    "        scope.reuse_variables()\n",
    "\n",
    "def get_scope_variable(scope_name, var_name):\n",
    "    with tf.variable_scope(scope_name, reuse=True):\n",
    "        v = tf.get_variable(var_name)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ckWall(xPos, yPos):\n",
    "    flagWall = 0\n",
    "    if(xPos < boundaryPos[0]):\n",
    "        xPos = boundaryPos[0]\n",
    "#         xPos = boundaryPos[0] + boundaryLength[0]\n",
    "        flagWall = -1\n",
    "    elif(xPos > boundaryPos[0] + boundaryLength[0]):\n",
    "        xPos = boundaryPos[0] + boundaryLength[0]\n",
    "#         xPos = boundaryPos[0]\n",
    "        flagWall = -1\n",
    "    if(yPos < boundaryPos[1]):\n",
    "        yPos = boundaryPos[1]\n",
    "#         yPos = boundaryPos[1] + boundaryLength[1]\n",
    "        flagWall = -1\n",
    "    elif(yPos > boundaryPos[1] + boundaryLength[1]):\n",
    "        yPos = boundaryPos[1] + boundaryLength[1]\n",
    "#         yPos = boundaryPos[1]\n",
    "        flagWall = -1\n",
    "    return [int(round(xPos)), int(round(yPos)), flagWall]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def takeAction(action):\n",
    "    xAction = 0\n",
    "    yAction = 0\n",
    "    actionOffset = 2\n",
    "    if action == 0:\n",
    "        xAction = actionOffset\n",
    "    elif action == 1:\n",
    "        xAction = actionOffset\n",
    "        yAction = actionOffset\n",
    "    elif action == 2:\n",
    "        xAction = actionOffset\n",
    "        yAction = -actionOffset\n",
    "    elif action == 3:\n",
    "        xAction = -actionOffset\n",
    "        yAction = actionOffset\n",
    "    elif action == 4:\n",
    "        xAction = -actionOffset\n",
    "    elif action == 5:\n",
    "        xAction = -actionOffset\n",
    "        yAction = -actionOffset\n",
    "    elif action == 6:\n",
    "        yAction = -actionOffset\n",
    "    elif action == 7:\n",
    "        yAction = actionOffset\n",
    "    elif action == 8:\n",
    "        xAction = 0\n",
    "        yAction = 0\n",
    "        \n",
    "    return [xAction, yAction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stateGenerator(intenPref, distPref):\n",
    "    returnSum = [intenPref, distPref]\n",
    "    returnSum = np.reshape(returnSum, [1, state_size])\n",
    "#     print returnSum\n",
    "    return returnSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rangeFinder(allObsPos, rangeCenter):\n",
    "    allObsAgtDistance = [0 for _ in range(obsNumber)]\n",
    "    for i in range(0, obsNumber):\n",
    "        allObsAgtDistance[i] = math.sqrt((allObsPos[i][0] - rangeCenter[0])**2 + (allObsPos[i][1] - rangeCenter[1])**2)\n",
    "    index = np.argmin(allObsAgtDistance)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,  [None, state_size], name = \"input_x\")\n",
    "initialize_variable(\"scope1\", \"W1\", [2, 1])\n",
    "W1 = get_scope_variable(\"scope1\", \"W1\")\n",
    "initialize_variable(\"scope1\", \"W2\", [1, 128])\n",
    "layer1 = tf.nn.relu(tf.matmul(X, W1))\n",
    "W2 = get_scope_variable(\"scope1\", \"W2\")\n",
    "initialize_variable(\"scope1\", \"W3\", [128, 1])\n",
    "layer2 = tf.nn.relu(tf.matmul(layer1, W2))\n",
    "W3 = get_scope_variable(\"scope1\", \"W3\")\n",
    "\n",
    "Qpred = tf.matmul(layer2, W3)\n",
    "Y = tf.placeholder(dtype = tf.float32)\n",
    "\n",
    "loss = tf.reduce_sum(tf.square(Y - Qpred))\n",
    "train = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Episode ', 0, 'Starts!')\n",
      "('Collision!', 3)\n",
      "-630.399016411\n",
      "('Episode ', 1, 'Starts!')\n",
      "('Collision!', 0)\n",
      "-795.418249066\n",
      "('Episode ', 2, 'Starts!')\n",
      "('Collision!', 1)\n",
      "-115.973373039\n",
      "('Episode ', 3, 'Starts!')\n",
      "Goal Reached!63 \n",
      "1910.11889904\n",
      "('Episode ', 4, 'Starts!')\n",
      "Goal Reached!49 \n",
      "1921.70362003\n",
      "('Episode ', 5, 'Starts!')\n",
      "('Collision!', 0)\n",
      "-41.7595657288\n",
      "('Episode ', 6, 'Starts!')\n",
      "Goal Reached!63  \n",
      "1927.12799104\n",
      "('Episode ', 7, 'Starts!')\n",
      "('Collision!', 0)\n",
      "-42.1048655251\n",
      "('Episode ', 8, 'Starts!')\n",
      "('Collision!', 0)\n",
      "-39.2738570896\n",
      "('Episode ', 9, 'Starts!')\n",
      "('Collision!', 0)       \n",
      "-10824.5362462\n",
      "('Episode ', 10, 'Starts!')\n",
      "('Collision!', 0)\n",
      "-23.8398000912\n",
      "('Episode ', 11, 'Starts!')\n",
      "('Collision!', 0)\n",
      "-47.317066575\n",
      "('Episode ', 12, 'Starts!')\n",
      "('Collision!', 0)                  \n",
      "-43901.019254\n",
      "('Episode ', 13, 'Starts!')\n",
      "('Collision!', 0)         \n",
      "-12836.2141185\n",
      "('Episode ', 14, 'Starts!')\n",
      "('Collision!', 0)\n",
      "-62.8373894162\n",
      "('Episode ', 15, 'Starts!')\n",
      "('Collision!', 0)\n",
      "-81.9825942425\n",
      "('Episode ', 16, 'Starts!')\n",
      "('Collision!', 0)   \n",
      "-12151.3994355\n",
      "('Episode ', 17, 'Starts!')\n",
      "('Collision!', 0)\n",
      "-67.5873918037\n",
      "('Episode ', 18, 'Starts!')\n",
      "('Collision!', 0)\n",
      "-41.4785200721\n",
      "('Episode ', 19, 'Starts!')\n",
      "('Collision!', 0)           \n",
      "-18331.8229826\n",
      "('Episode ', 20, 'Starts!')\n",
      "('Collision!', 0) \n",
      "-3095.15254922\n",
      "('Episode ', 21, 'Starts!')\n",
      "('Collision!', 0)     \n",
      "-12496.4891183\n",
      "('Episode ', 22, 'Starts!')\n",
      "('Collision!', 0)\n",
      "-881.607148366\n",
      "('Episode ', 23, 'Starts!')\n",
      "('Collision!', 0)\n",
      "-31.9050098055\n",
      "('Episode ', 24, 'Starts!')\n",
      "('Collision!', 0)\n",
      "-33.9927281657\n",
      "('Episode ', 25, 'Starts!')\n",
      "('Collision!', 0)\n",
      "-905.286043609\n",
      "('Episode ', 26, 'Starts!')\n",
      "('Collision!', 0)          \n",
      "-15481.7085418\n",
      "('Episode ', 27, 'Starts!')\n",
      "('Collision!', 0)\n",
      "-33.0068483036\n",
      "('Episode ', 28, 'Starts!')\n",
      "('Collision!', 0)    \n",
      "-16903.3324655\n",
      "('Episode ', 29, 'Starts!')\n",
      "('Collision!', 0)\n",
      "-28.0423745905\n",
      "('Episode ', 30, 'Starts!')\n",
      "('Collision!', 0)                                                                                                         \n",
      "-215496.910316\n",
      "('Episode ', 31, 'Starts!')\n",
      "('Collision!', 0)\n",
      "-36.1425207044\n",
      "('Episode ', 32, 'Starts!')\n",
      "('Collision!', 0)                     \n",
      "-40603.1438572\n",
      "('Episode ', 33, 'Starts!')\n",
      "('Collision!', 0)\n",
      "-44.8119986623\n",
      "('Episode ', 34, 'Starts!')\n",
      "('Collision!', 0)\n",
      "-38.4992263145\n",
      "('Episode ', 35, 'Starts!')\n",
      "-0.708903378466                                                                                                 \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6f4994a85c5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mtmpX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtmpXMove\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mtmpY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtmpYMove\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                 \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrangeFinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobstaclePos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtmpX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtmpY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0mFeatureVec1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtmpX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minitPosGoal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtmpY\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minitPosGoal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mFeatureVec2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100000.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtmpX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mobstaclePos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtmpY\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mobstaclePos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-3557b0120ec8>\u001b[0m in \u001b[0;36mrangeFinder\u001b[0;34m(allObsPos, rangeCenter)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrangeFinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallObsPos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrangeCenter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mallObsAgtDistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobsNumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobsNumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mallObsAgtDistance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallObsPos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrangeCenter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mallObsPos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrangeCenter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallObsAgtDistance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#display\n",
    "pygame.init()\n",
    "screen = pygame.display.set_mode([300,300])\n",
    "screen.fill([200, 200, 200])\n",
    "\n",
    "episodeNo = []\n",
    "scorePlot = []\n",
    "\n",
    "obsAngleIdx = 0\n",
    "# Make Obstacles (obsNumber)\n",
    "obstaclePos = [[0, 0] for _ in range(obsNumber)]\n",
    "posOffset = 60\n",
    "obstaclePos[0][0] = int(initPosGoal[0] + posOffset) \n",
    "obstaclePos[0][1] = int(initPosGoal[1]) \n",
    "obstaclePos[1][0] = int(initPosGoal[0]) \n",
    "obstaclePos[1][1] = int(initPosGoal[1] + posOffset) \n",
    "obstaclePos[2][0] = int(initPosGoal[0] - posOffset) \n",
    "obstaclePos[2][1] = int(initPosGoal[1]) \n",
    "obstaclePos[3][0] = int(initPosGoal[0]) \n",
    "obstaclePos[3][1] = int(initPosGoal[1] - posOffset) \n",
    "beta = 0.0\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    Qs = np.zeros(action_size)\n",
    "#     Qs = [0 for _ in range(action_size)]\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        done = False\n",
    "        score = 0\n",
    "        x = initPosAgent[0]\n",
    "        y = initPosAgent[1]\n",
    "        print(\"Episode \", episode, \"Starts!\")\n",
    "#         goalRadius = initGoalRadius - episode / 25\n",
    "        xMove = 0\n",
    "        yMove = 0\n",
    "        idx = rangeFinder(obstaclePos, [x,y])\n",
    "        FeatureVec1 = (x - initPosGoal[0])**2 + (y - initPosGoal[1])**2\n",
    "        FeatureVec2 = 100000.0 / (beta + (x - obstaclePos[idx][0])**2 + (y - obstaclePos[idx][1])**2)\n",
    "#         FeatureVec2 = (x - obstaclePos[idx][0])**2 + (y - obstaclePos[idx][1])**2\n",
    "\n",
    "        state = stateGenerator(FeatureVec1, FeatureVec2)\n",
    "        e = 1.0 / ((episode/100.0) + 1.0)\n",
    "#             e = 0.01\n",
    "#         e = 1.0 / (1.0 + episode / 100.0)\n",
    "        rAll = 0\n",
    "        step_count = 0\n",
    "        while not done:\n",
    "            step_count += 1\n",
    "            Qinput = np.reshape(state, [1, state_size])\n",
    "            \n",
    "            for i in range(0,action_size):\n",
    "                [tmpXMove, tmpYMove] = takeAction(i)\n",
    "                tmpX = x + tmpXMove\n",
    "                tmpY = y + tmpYMove\n",
    "                idx = rangeFinder(obstaclePos, [tmpX,tmpY])\n",
    "                FeatureVec1 = (tmpX - initPosGoal[0])**2 + (tmpY - initPosGoal[1])**2\n",
    "                FeatureVec2 = 100000.0 / (beta + (tmpX - obstaclePos[idx][0])**2 + (tmpY - obstaclePos[idx][1])**2)\n",
    "#                 FeatureVec2 = (tmpX - obstaclePos[idx][0])**2 + (tmpY - obstaclePos[idx][1])**2\n",
    "                tmpNextState = stateGenerator(FeatureVec1, FeatureVec2)\n",
    "                QinputPred = np.reshape(tmpNextState, [1, state_size])\n",
    "                Qs[i] = sess.run(Qpred, feed_dict = {X: QinputPred})\n",
    "#             print Qs\n",
    "#             print \"========================================\"\n",
    "            if np.random.rand(1) < e:\n",
    "                action = random.randrange(0,8)\n",
    "            else:\n",
    "                action = np.argmax(Qs)\n",
    "#             print action\n",
    "            xMove = 0\n",
    "            yMove = 0\n",
    "            [xMove, yMove] = takeAction(action)\n",
    "\n",
    "            x = x + xMove\n",
    "            y = y + yMove\n",
    "            \n",
    "            wallFlag = 0\n",
    "            collisionFlag = 0\n",
    "            [x, y, wallFlag] = ckWall(x, y)\n",
    "            pygame.draw.circle(screen, [100,100,255],[x,y],agentRadius,0)\n",
    "            idx = rangeFinder(obstaclePos, [x,y])\n",
    "            FeatureVec1 = (x - initPosGoal[0])**2 + (y - initPosGoal[1])**2\n",
    "            FeatureVec2 = 100000.0 / (beta + (tmpX - obstaclePos[idx][0])**2 + (tmpY - obstaclePos[idx][1])**2)\n",
    "#             FeatureVec2 = (x - obstaclePos[idx][0])**2 + (y - obstaclePos[idx][1])**2\n",
    "            next_state = stateGenerator(FeatureVec1, FeatureVec2)\n",
    "            ## Draw Environment (Obstacle + Map)\n",
    "            if(math.sqrt((x - initPosGoal[0])**2 + (y - initPosGoal[1])**2) <= goalRadius + agentRadius):\n",
    "                print(\"Goal Reached!\")\n",
    "                reward = 2000.0\n",
    "                collisionFlag = 1\n",
    "                done = True\n",
    "            for i in range(0,obsNumber):\n",
    "                pygame.draw.circle(screen, [255, 50, 50], obstaclePos[i], obstacleRadius, 0)\n",
    "                if math.sqrt((x - obstaclePos[i][0])**2 + (y - obstaclePos[i][1])**2) <= obstacleRadius + agentRadius:\n",
    "                    print(\"Collision!\", idx)\n",
    "                    reward = -15.0\n",
    "                    collisionFlag = -1\n",
    "                    done = True\n",
    "                    break\n",
    "            Qinput1 = np.reshape(next_state, [1, state_size])\n",
    "            \n",
    "            if not done:\n",
    "                reward = -7.0 * math.sqrt((x - initPosGoal[0])**2 + (y - initPosGoal[1])**2) / 1000.0\n",
    "#                 reward = 0\n",
    "                QcurrPred = reward + dis * Qs[action]\n",
    "            \n",
    "            score += reward\n",
    "            \n",
    "            if done:\n",
    "                episodeNo = episodeNo + [episode]\n",
    "                if collisionFlag == 1:\n",
    "                    QcurrPred = 2000.0\n",
    "                    rList.append(1)\n",
    "                elif collisionFlag == -1:\n",
    "                    QcurrPred = -15.0\n",
    "                    rList.append(0)\n",
    "#             Qs1 = sess.run(Qpred, feed_dict = {X: Qinput1})\n",
    "                print score\n",
    "                scorePlot = scorePlot + [score]\n",
    "#             QcurrPred = reward + dis * np.max(Qs)\n",
    "\n",
    "            print QcurrPred, '\\r',\n",
    "            sess.run(train, feed_dict={X: Qinput1, Y: QcurrPred})\n",
    "            state = next_state\n",
    "\n",
    "            if done:\n",
    "                if collisionFlag == 1:\n",
    "                    if initPosAgent[0] >= boundaryPos[0] + boundaryLength[0] / 2 + 50 and initPosAgent[0] <= boundaryPos[0] + boundaryLength[0] / 2 + 99:\n",
    "                        initPosAgent[1] = initPosAgent[1] - 1\n",
    "                        initPosAgent[0] = initPosAgent[0] + 1\n",
    "                    elif initPosAgent[0] < boundaryPos[0] + boundaryLength[0] / 2 + 50:\n",
    "                        initPosAgent[0] = initPosAgent[0] + 1\n",
    "                        initPosAgent[1] = initPosAgent[1] + 1\n",
    "                \n",
    "                for i in range(0,obsNumber):\n",
    "                    pygame.draw.circle(screen, [255, 50, 50], obstaclePos[i], obstacleRadius, 0)\n",
    "                if episode % 100 == 0:\n",
    "                    plt.plot(episodeNo, scorePlot, linewidth = 0.3)\n",
    "                    plt.savefig(\"/home/howoongjun/RLPractice/Practice/DataSave/RewardPlot.png\", dpi=300)\n",
    "            pygame.draw.circle(screen, [100,255,100], initPosGoal, goalRadius, 1)\n",
    "            pygame.draw.rect(screen, [255,100,100],[boundaryPos[0],boundaryPos[1], boundaryLength[0], boundaryLength[1]],1)\n",
    "            pygame.display.flip()\n",
    "            screen.fill([200,200,200])\n",
    "#             print sess.run(loss, feed_dict = {X:Qinput, Y:QcurrPred}), '\\r',\n",
    "#             print sess.run(Qpred, feed_dict = {X: QinputPred}), '\\r',\n",
    "            \n",
    "    print sess.run(W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[[0.15473302] [0.449626  ]]\n",
    "    \n",
    "[[0.34095567] [0.54793298]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Converged: 6\n",
    "Diverged: 8\n",
    "Local Minima: 13"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
