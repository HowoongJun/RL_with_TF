{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pygame, sys, random\n",
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import datetime\n",
    "\n",
    "num_episodes = 300\n",
    "\n",
    "obstacleRadius = 10\n",
    "agentRadius = 10\n",
    "\n",
    "# get size of state and action from environment\n",
    "\n",
    "boundaryPos = [100, 100]\n",
    "boundaryLength = [0,0]\n",
    "boundaryRadius = 40\n",
    "initPosAgent = [boundaryPos[0] + boundaryLength[0] / 2 + 100, boundaryPos[1] + boundaryLength[1] / 2]\n",
    "initPosGoal =  [boundaryPos[0] + boundaryLength[0] / 2, boundaryPos[1] + boundaryLength[1] / 2]\n",
    "goalPos = [boundaryPos[0] + boundaryLength[0], boundaryPos[1] + boundaryLength[1]/2]\n",
    "goalAngle = 0#random.randrange(0, 360) * math.pi / 180\n",
    "\n",
    "obsAngleUnit = 6\n",
    "\n",
    "moveObstacles = False\n",
    "action_size = 8\n",
    "obsNumber = 4\n",
    "state_size = 4\n",
    "# state_size = obsNumber + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A2C(Advantage Actor-Critic) agent\n",
    "class A2CAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.load_model = False\n",
    "        \n",
    "        # get size of state and action\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.value_size = 1\n",
    "\n",
    "        # These are hyper parameters for the Policy Gradient\n",
    "        self.discount_factor = 0.99\n",
    "        self.actor_lr = 0.00002\n",
    "        self.critic_lr = 0.00005\n",
    "\n",
    "        # create model for policy network\n",
    "        self.actor = self.build_actor()\n",
    "        self.critic = self.build_critic()\n",
    "        \n",
    "        if self.load_model:\n",
    "            self.actor.load_weights(\"./Practice004_DataSave/Actor_PEARL.h5\")\n",
    "            self.critic.load_weights(\"./Practice004_DataSave/Critic_PEARL.h5\")\n",
    "        print self.actor.get_weights()[0]\n",
    "    # approximate policy and value using Neural Network\n",
    "    # actor: state is input and probability of each action is output of model\n",
    "    def build_actor(self):\n",
    "        actor = Sequential()\n",
    "        actor.add(Dense(1, input_dim=self.state_size, activation='relu', kernel_initializer='glorot_normal'))\n",
    "        actor.add(Dense(self.action_size, activation='softmax', kernel_initializer='glorot_normal'))\n",
    "        actor.summary()\n",
    "        # See note regarding crossentropy in cartpole_reinforce.py\n",
    "        actor.compile(loss='categorical_crossentropy', optimizer=Adam(lr=self.actor_lr))\n",
    "        return actor\n",
    "\n",
    "    # critic: state is input and value of state is output of model\n",
    "    def build_critic(self):\n",
    "        critic = Sequential()\n",
    "        critic.add(Dense(1, input_dim=self.state_size, activation='relu', kernel_initializer='glorot_normal'))\n",
    "        critic.add(Dense(self.value_size, activation='linear', kernel_initializer='glorot_normal'))\n",
    "        critic.summary()\n",
    "        critic.compile(loss=\"mse\", optimizer=Adam(lr=self.critic_lr))\n",
    "        return critic\n",
    "\n",
    "    # using the output of policy network, pick action stochastically\n",
    "    def get_action(self, state):\n",
    "        policy = self.actor.predict(state, batch_size=1).flatten()\n",
    "#         print policy\n",
    "        return np.random.choice(self.action_size, 1, p=policy)[0]\n",
    "\n",
    "    # update policy network every episode\n",
    "    def train_model(self, state, action, reward, next_state, done):\n",
    "        target = np.zeros((1, self.value_size))\n",
    "        advantages = np.zeros((1, self.action_size))\n",
    "\n",
    "        value = self.critic.predict(state)[0]\n",
    "        next_value = self.critic.predict(next_state)[0]\n",
    "\n",
    "        if done:\n",
    "            advantages[0][action] = reward - value\n",
    "            target[0][0] = reward\n",
    "        else:\n",
    "            advantages[0][action] = reward + self.discount_factor * (next_value) - value\n",
    "            target[0][0] = reward + self.discount_factor * next_value\n",
    "\n",
    "        self.actor.fit(state, advantages, epochs=1, verbose=0)\n",
    "        self.critic.fit(state, target, epochs=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ckWall(xPos, yPos):\n",
    "    if math.sqrt((xPos - initPosAgent[0]) ** 2 + (yPos - initPosAgent[1]) ** 2) > boundaryRadius - obstacleRadius:\n",
    "        if xPos - initPosAgent[0] != 0:\n",
    "            xPos = xPos - (xPos - initPosAgent[0])/abs(xPos - initPosAgent[0])\n",
    "        if yPos - initPosAgent[1] != 0:\n",
    "            yPos = yPos - (yPos - initPosAgent[1])/abs(yPos - initPosAgent[1])\n",
    "    return [int(round(xPos)), int(round(yPos))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stateGenerator(agtVelocity, agtPosition):\n",
    "    returnSum = [agtPosition, agtVelocity]\n",
    "    returnSum = np.reshape(returnSum, [1, state_size])\n",
    "    return returnSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def takeAction(action):\n",
    "    xAction = 0\n",
    "    yAction = 0\n",
    "    if action == 0:\n",
    "        xAction = 1\n",
    "    elif action == 1:\n",
    "        xAction = 1\n",
    "        yAction = 1\n",
    "    elif action == 2:\n",
    "        xAction = 1\n",
    "        yAction = -1            \n",
    "    elif action == 3:\n",
    "        xAction = -1\n",
    "        yAction = 1\n",
    "    elif action == 4:\n",
    "        xAction = -1\n",
    "    elif action == 5:\n",
    "        xAction = -1\n",
    "        yAction = -1\n",
    "    elif action == 6:\n",
    "        yAction = -1\n",
    "    elif action == 7:\n",
    "        yAction = 1\n",
    "#     elif action == 8:\n",
    "#         xAction = 0\n",
    "#         yAction = 0\n",
    "        \n",
    "    return [xAction, yAction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               640       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 1,672\n",
      "Trainable params: 1,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/howoongjun/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:2885: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/howoongjun/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 128)               640       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 769\n",
      "Trainable params: 769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[[  1.35195050e-02   1.87007800e-01  -1.05922939e-02  -8.03808942e-02\n",
      "   -1.23749310e-02  -1.03223830e-01  -2.09400386e-01  -1.27278984e-01\n",
      "   -1.83357850e-01  -1.29582705e-02  -1.74191177e-01  -4.62969318e-02\n",
      "    1.58399791e-01   5.29397279e-03   1.01369590e-01   1.66207343e-01\n",
      "   -1.47221148e-01   6.90701753e-02  -7.47818351e-02  -6.23468012e-02\n",
      "    9.12264660e-02   3.18823494e-02  -3.71297337e-02  -1.30675677e-02\n",
      "    1.35743037e-01  -7.81020448e-02  -8.84981230e-02  -1.95940927e-01\n",
      "    4.59393524e-02  -1.03995606e-01  -9.95355248e-02   1.81265280e-01\n",
      "    2.62935124e-02   6.20747730e-02   1.11221015e-01   3.77972946e-02\n",
      "    4.69592540e-03   2.13698894e-02  -8.54469240e-02  -1.42012611e-01\n",
      "    1.11691244e-01  -2.74120718e-02  -8.17384273e-02  -9.74290669e-02\n",
      "    7.33127519e-02   1.78390183e-02   1.64002612e-01   8.69070645e-03\n",
      "    6.99642897e-02   7.60395080e-02   1.48221865e-01  -1.55547619e-01\n",
      "   -1.04422597e-02   9.33135524e-02  -2.78194388e-03  -2.10212097e-01\n",
      "   -5.45277633e-02  -2.27977857e-02  -7.56537542e-02   3.83898057e-02\n",
      "    2.10916340e-01  -4.47734855e-02   1.83596820e-01   9.37682763e-02\n",
      "    6.36918843e-02   3.75264436e-02   9.96787176e-02   5.22128455e-02\n",
      "   -3.12020686e-02  -7.39204437e-02   6.98059648e-02   1.11992337e-01\n",
      "   -1.05539553e-01   1.11452848e-01   3.04527171e-02  -9.70805734e-02\n",
      "    3.35367434e-02   5.22702895e-02   9.79271606e-02   9.62223411e-02\n",
      "    1.08269282e-01  -9.39735547e-02  -1.93321109e-01   9.04809535e-02\n",
      "   -2.18928009e-02   1.16443753e-01   1.30354285e-01  -1.96970284e-01\n",
      "    2.27411672e-01  -2.02521846e-01   5.14031202e-02   1.58579677e-01\n",
      "   -1.22818545e-01  -5.15375435e-02  -1.30038694e-01  -1.77660927e-01\n",
      "   -3.90513130e-02   6.41500484e-03   2.91422177e-02   5.81106171e-02\n",
      "   -7.34889358e-02  -5.41454889e-02   8.58804509e-02   2.07733229e-01\n",
      "   -1.87384076e-02   6.17558844e-02   2.22093821e-01   1.12405248e-01\n",
      "   -8.03764611e-02  -7.53099984e-03   1.45981163e-01   1.51552126e-01\n",
      "    3.65440100e-02   1.76583044e-02  -1.71422049e-01  -4.14504297e-02\n",
      "   -9.72582400e-02  -1.22021250e-01  -1.60945579e-02  -1.08465552e-01\n",
      "   -2.25739121e-01  -1.88367099e-01  -2.43859872e-01  -1.33015379e-01\n",
      "   -1.91308573e-01   5.77710010e-02   7.52703147e-03   1.25145406e-01]\n",
      " [  4.63415757e-02  -7.28954747e-02   3.67267281e-02   2.06860214e-01\n",
      "   -1.13357395e-01  -1.61579803e-01  -9.96567905e-02   6.66308776e-02\n",
      "   -1.21521831e-01  -2.14528397e-01   8.75844955e-02   7.31137767e-02\n",
      "   -3.77122723e-02   2.69931741e-02   3.66364643e-02  -1.91941962e-01\n",
      "    5.54382280e-02  -2.78185569e-02  -1.14063047e-01   7.66822621e-02\n",
      "   -8.40582177e-02  -2.04201296e-01   6.85801804e-02   1.07798897e-01\n",
      "   -1.39254287e-01   1.54926851e-01   1.44005552e-01  -3.11943069e-02\n",
      "   -1.31366879e-01  -1.78263143e-01   7.17737302e-02   2.27315709e-01\n",
      "   -1.85469419e-01   5.71130551e-02   2.22178966e-01   5.48300371e-02\n",
      "    2.22099479e-02  -1.66404352e-01   2.44161189e-01  -3.60196196e-02\n",
      "   -1.37171239e-01  -6.82574585e-02   1.63308028e-02  -1.61418170e-02\n",
      "    4.58924426e-03  -4.68652658e-02   1.32588387e-01  -2.17106212e-02\n",
      "   -8.52757543e-02  -3.39127444e-02   1.02667339e-01   1.80243418e-01\n",
      "   -1.34027734e-01  -1.37307093e-01   6.90819770e-02   7.83362687e-02\n",
      "   -1.31562069e-01   4.40790206e-02   2.82149557e-02  -7.05905333e-02\n",
      "    9.53648314e-02  -4.35388386e-02   7.96596855e-02  -1.06454641e-01\n",
      "    4.09376137e-02  -1.30651549e-01  -2.02211160e-02  -2.60494631e-02\n",
      "   -1.42900879e-02  -5.76454848e-02   3.03503033e-02  -9.00357775e-03\n",
      "    1.89393628e-02  -8.00033584e-02  -8.12932476e-02   1.95342992e-02\n",
      "    8.86611491e-02  -3.11869499e-03  -1.43107265e-01   1.75945595e-01\n",
      "   -2.13539362e-01  -1.19447205e-02   4.41010259e-02  -2.13245869e-01\n",
      "    1.47888824e-01  -1.32119358e-01   1.12265117e-01   6.69253767e-02\n",
      "   -1.57315820e-01  -9.71558914e-02  -3.65544930e-02  -1.17862791e-01\n",
      "   -1.62090749e-01  -1.26519157e-02  -1.33492768e-01  -3.25271077e-02\n",
      "   -6.47049546e-02   3.00105177e-02  -6.35036007e-02   6.92447275e-02\n",
      "   -3.29167061e-02  -1.36653751e-01  -1.10496953e-01  -1.73164561e-01\n",
      "   -5.23971133e-02   1.17167681e-01   3.51604186e-02   4.52950336e-02\n",
      "   -1.35394990e-01  -6.35369346e-02   3.15359160e-02   1.09403029e-01\n",
      "    6.47238567e-02  -1.75577775e-01   3.27181593e-02  -1.69650409e-02\n",
      "    9.61166620e-02   1.90986633e-01  -1.18047111e-01  -1.15067102e-01\n",
      "   -2.13746712e-01   6.02709576e-02  -1.73306048e-01  -8.66879895e-02\n",
      "   -1.60050839e-01  -2.37157829e-02  -6.56715855e-02  -4.67275009e-02]\n",
      " [ -8.97956565e-02   2.53108591e-02  -1.20458044e-01   4.18905318e-02\n",
      "   -7.65797943e-02  -9.57067907e-02   1.46748036e-01  -2.66958158e-02\n",
      "    1.60323337e-01   2.80921906e-02   4.64968905e-02   1.30464971e-01\n",
      "   -1.21776246e-01   8.41644406e-02   5.97678795e-02   1.53289735e-01\n",
      "    1.17814966e-01  -1.39746264e-01   1.75730839e-01   9.71268639e-02\n",
      "   -1.06146142e-01  -9.51082781e-02  -1.11295737e-01   8.68377462e-03\n",
      "   -4.99007516e-02   2.22160500e-02  -5.90411127e-02  -2.42711734e-02\n",
      "   -1.67178258e-01   1.62294105e-01   1.24730416e-01   1.24297831e-02\n",
      "    7.34653771e-02  -2.19198868e-01   1.17551699e-01   9.81636997e-03\n",
      "    4.87547405e-02  -8.27924535e-02  -8.40125419e-03  -9.52757820e-02\n",
      "    9.43964813e-03  -7.71806911e-02   8.01821798e-03   2.80794185e-02\n",
      "    2.05366816e-02  -4.25577611e-02  -3.25395912e-02  -1.88484028e-01\n",
      "   -2.10698590e-01   2.21963510e-01  -1.76767305e-01  -1.99751467e-01\n",
      "   -1.18879594e-01  -7.36725181e-02   1.98474586e-01   1.82935745e-01\n",
      "    6.82379026e-03   2.02845950e-02  -1.47918135e-01  -1.97535619e-01\n",
      "   -1.65195167e-02  -1.24066966e-02  -9.93631333e-02  -9.74855293e-03\n",
      "   -7.22343102e-02  -1.79908872e-01   1.85513496e-02  -2.28198752e-01\n",
      "   -2.97523122e-02  -1.06581852e-01   1.13878094e-01  -6.71097189e-02\n",
      "    1.11651272e-01  -3.16021852e-02   8.71561319e-02  -5.68033606e-02\n",
      "    1.74530715e-01  -6.84367269e-02   5.47582358e-02   6.01424426e-02\n",
      "    1.52803898e-01  -2.66629178e-02  -1.95752874e-01  -2.09012087e-02\n",
      "    7.32623711e-02   3.93515872e-03  -7.58725703e-02  -1.90574884e-01\n",
      "    8.06180164e-02  -1.09847642e-01   8.12360644e-02  -1.72057226e-02\n",
      "   -1.27072260e-01  -2.77880505e-02   2.38294825e-01  -1.80051684e-01\n",
      "    5.66520765e-02  -1.34375185e-01  -1.06355892e-02   1.68360293e-01\n",
      "   -2.30900452e-01   5.88240549e-02   1.10143922e-01   1.26383856e-01\n",
      "    5.43214455e-02  -1.22723088e-01   7.11636022e-02   1.47094131e-01\n",
      "    9.60419700e-02   7.18671754e-02   4.11297232e-02  -3.78521271e-02\n",
      "   -1.96331888e-01  -1.08848721e-01   1.81890339e-01  -4.85212170e-03\n",
      "    6.06237650e-02   1.77532092e-01   3.71110104e-02  -7.82949626e-02\n",
      "   -1.82916880e-01   2.08835930e-01  -1.75208244e-02   2.38905046e-02\n",
      "   -1.30065501e-01   1.41790453e-02   1.23475321e-01  -1.39168128e-01]\n",
      " [ -7.02830479e-02   2.35119127e-02  -6.22398965e-02  -8.72842148e-02\n",
      "    1.57574341e-01  -9.95896608e-02  -1.21178932e-01  -1.36539251e-01\n",
      "   -9.29054692e-02  -8.14877748e-02  -8.49505365e-02   4.09629941e-03\n",
      "    3.72348949e-02   1.77192409e-02   3.43655422e-03   5.70053281e-03\n",
      "    1.48659229e-01   1.05386367e-02   2.38071173e-01  -2.18957230e-01\n",
      "    1.43174946e-01  -4.78752255e-02   1.78524837e-01  -6.95284531e-02\n",
      "    1.12530813e-02  -2.26742774e-01  -1.60379857e-01   5.54206409e-02\n",
      "   -1.11786172e-01  -2.87736636e-02  -1.04547761e-01  -2.06956252e-01\n",
      "   -1.83034107e-01  -1.71764672e-01   9.01245046e-03  -1.92726910e-01\n",
      "    3.91095951e-02  -1.72481433e-01  -3.92057896e-02   3.82024422e-02\n",
      "   -8.41113105e-02  -2.36271918e-01  -5.54452837e-02   7.34641179e-02\n",
      "    1.66297425e-04  -8.20568055e-02  -2.47920845e-02   6.98234886e-02\n",
      "   -8.98833349e-02   1.09507106e-01  -5.63901775e-02   1.38075143e-01\n",
      "   -4.87907417e-02  -1.54933445e-02   1.32269546e-01  -1.11066937e-01\n",
      "   -4.86503914e-02   6.05090000e-02   1.67931810e-01   1.83685403e-02\n",
      "   -5.92088401e-02  -6.72043040e-02  -1.06223270e-01   8.81676935e-03\n",
      "    2.41110861e-01   9.62165594e-02  -6.51854742e-03  -2.28086803e-02\n",
      "   -3.10820416e-02   7.71621242e-03  -1.31307349e-01  -5.52239865e-02\n",
      "    7.61913136e-02  -1.54313996e-01   5.78107722e-02   4.36620228e-02\n",
      "    5.44483587e-02  -1.03484103e-02  -7.75578469e-02   4.43794653e-02\n",
      "   -8.15277696e-02  -2.00472862e-01   1.11080825e-01  -8.75692666e-02\n",
      "    9.51487049e-02  -7.72120524e-03   8.34084973e-02   2.48734485e-02\n",
      "    1.06362998e-02   1.26052991e-01   5.45295402e-02  -7.10091218e-02\n",
      "   -6.22250549e-02  -1.74759492e-01  -2.73233019e-02   1.84982922e-02\n",
      "   -2.11375151e-02   1.54897869e-01   1.87048763e-01  -2.00661272e-01\n",
      "    1.74684495e-01  -6.38201237e-02   1.47970421e-02   2.32931338e-02\n",
      "    1.35020083e-02   1.56689093e-01  -2.15362355e-01  -2.40557292e-03\n",
      "   -2.05624714e-01  -1.33982562e-02   1.24637298e-01   2.09080819e-02\n",
      "    1.39897510e-01  -1.58915833e-01  -1.17778592e-01  -9.17768627e-02\n",
      "    7.70270154e-02   1.03250220e-01  -2.26688161e-01  -7.99454525e-02\n",
      "    1.31041676e-01  -9.50633585e-02  -9.89919528e-02  -1.03247806e-01\n",
      "   -1.26900315e-01  -1.17636539e-01  -1.72415674e-01   1.79596156e-01]]\n",
      "('Episode ', 0, 'Starts!')\n"
     ]
    }
   ],
   "source": [
    "pygame.init()\n",
    "screen = pygame.display.set_mode([300,300])\n",
    "screen.fill([200, 200, 200])\n",
    "\n",
    "# make A2C agent\n",
    "agent = A2CAgent(state_size, action_size)\n",
    "\n",
    "rList, episodes = [], []\n",
    "obsAngleIdx = 0\n",
    "# Make Obstacles (obsNumber)\n",
    "obstaclePos = [[0, 0] for _ in range(obsNumber)]\n",
    "obstaclePos[0][0] = int(initPosGoal[0] + 60) \n",
    "obstaclePos[0][1] = int(initPosGoal[1]) \n",
    "obstaclePos[1][0] = int(initPosGoal[0]) \n",
    "obstaclePos[1][1] = int(initPosGoal[1] + 60) \n",
    "obstaclePos[2][0] = int(initPosGoal[0] - 60) \n",
    "obstaclePos[2][1] = int(initPosGoal[1]) \n",
    "obstaclePos[3][0] = int(initPosGoal[0]) \n",
    "obstaclePos[3][1] = int(initPosGoal[1] - 60) \n",
    "\n",
    "for e in range(num_episodes):\n",
    "    # Initialize\n",
    "    done = False\n",
    "    score = 0\n",
    "    x = initPosAgent[0]\n",
    "    y = initPosAgent[1]\n",
    "    print(\"Episode \", e, \"Starts!\")\n",
    "    \n",
    "    xMove = 0\n",
    "    yMove = 0\n",
    "    \n",
    "    state = stateGenerator([xMove, yMove], [x,y])\n",
    "    while not done:\n",
    "        \n",
    "        action = agent.get_action(state)\n",
    "        \n",
    "        [xMove, yMove] = takeAction(action)\n",
    "        \n",
    "        x = x + xMove\n",
    "        y = y + yMove\n",
    "        \n",
    "        wallFlag = 0\n",
    "        collisionFlag = 0\n",
    "        pygame.draw.circle(screen, [100, 100, 255], [x,y], 10, 0)\n",
    "        next_state = stateGenerator([xMove,  yMove], [x,y])\n",
    "\n",
    "        if(math.sqrt((x - initPosGoal[0])**2 + (y - initPosGoal[1])**2) <= obstacleRadius + agentRadius):\n",
    "            print(\"Goal Reached!\")\n",
    "            collisionFlag = 1\n",
    "            done = True\n",
    "        for i in range(0,obsNumber):\n",
    "            pygame.draw.circle(screen, [255, 50, 50], obstaclePos[i], obstacleRadius, 0)\n",
    "            if math.sqrt((x - obstaclePos[i][0])**2 + (y - obstaclePos[i][1])**2) <= obstacleRadius + agentRadius:\n",
    "                print(\"Collision!\")\n",
    "                collisionFlag = -1\n",
    "                done = True\n",
    "        \n",
    "        if not done:\n",
    "            reward = 0\n",
    "        else:\n",
    "            if collisionFlag == 1:\n",
    "                reward = 10\n",
    "                rList.append(1)\n",
    "            elif collisionFlag == -1:\n",
    "                reward = -15\n",
    "                rList.append(0)\n",
    "        \n",
    "        agent.train_model(state, action, reward, next_state, done)\n",
    "        \n",
    "        score += reward\n",
    "        state = next_state\n",
    "        if done:\n",
    "            episodes.append(e)\n",
    "        pygame.display.flip()\n",
    "        screen.fill([200,200,200])\n",
    "    print(datetime.datetime.now().strftime('%H:%M:%S'), score)\n",
    "    print \"====================================================================================================\"\n",
    "    # save the model\n",
    "    if e % 50 == 0:\n",
    "        agent.actor.save_weights(\"./Practice004_DataSave/Actor_PEARL.h5\")\n",
    "        agent.critic.save_weights(\"./Practice004_DataSave/Critic_PEARL.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Percent of successful episodes: \" + str(100.0 * sum(rList)/num_episodes) + \"%\")\n",
    "\n",
    "# plt.bar(range(len(rList)), rList, color = \"Blue\", width = 0.00001)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
